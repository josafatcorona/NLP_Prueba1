{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cdbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e19e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(r'Corpus_crucero.txt','r',errors = 'ignore')\n",
    "raw=f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42104bc9",
   "metadata": {},
   "source": [
    "# 2a Preprocesamiento del Texto con NTLK CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7be084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=raw.lower()# convertir en minúscula\n",
    "#nltk.download('punkt') # Instalar módulo punkt si no está ya instalado (solo ejecutar la primera vez)\n",
    "#nltk.download('wordnet') # Instalar módulo wordnet si no está ya instalado (solo ejecutar la primera vez)\n",
    "sent_tokens = nltk.sent_tokenize(raw)# Convierte el CORPUS a una lista de sentencias\n",
    "word_tokens = nltk.word_tokenize(raw)# Convierte el CORPUS a una lista de palabras\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#WordNet diccionario semántico incluido en NLTK\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964cdb3",
   "metadata": {},
   "source": [
    "# 2b PREPROCESAMIENTO DEL TEXTO + 3 Evaluar Similitud MENSAJE USUARIO - CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84697b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Función para determinar la similitud del texto insertado y el corpus\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response) #Añade al corpus la respuesta de usuario al final\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words('spanish'))\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    # 3 EVALUAR SIMILITUD DE COSENO ENTRE MENSAJE USUARIO (tfidf[-1]) y el CORPUS (tfidf)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    \n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"Lo siento, no te he entendido. Si no puedo responder a lo que busca póngase en contacto con soporte@soporte.com\"\n",
    "        return robo_response\n",
    "\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a80fab",
   "metadata": {},
   "source": [
    "# 4 DEFINICIÓN DE COINCIDENCIAS MANUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c44aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALUDOS_INPUTS = (\"hola\", \"buenas\", \"saludos\", \"qué tal\", \"hey\",\"buenos dias\",)\n",
    "SALUDOS_OUTPUTS = [\"Hola\", \"Hola, ¿Qué tal?\", \"Hola, ¿Cómo te puedo ayudar?\", \"Hola, encantado de hablar contigo\"]\n",
    "\n",
    "def saludos(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in SALUDOS_INPUTS:\n",
    "            return random.choice(SALUDOS_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6003e0",
   "metadata": {},
   "source": [
    "# 5 GENERACIÓN DE RESPUESTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8825b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT: Mi nombre es ROBOT. Contestaré a tus preguntas acerca de sus vacaciones en el crucero. Si quieres salir, escribe 'salir' \n",
      "Hola\n",
      "ROBOT: Hola, ¿Qué tal?\n",
      "gracias\n",
      "ROBOT: No hay de qué\n",
      "se puede fumar en el crucero?\n",
      "ROBOT: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\VirtualEnvs\\NLP_course\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "está prohibido fumar en los teatros, en los restaurantes y buffet de autoservicio (locales cerrados), en los corredores, pasillos, vestíbulos, antesalas e interiores de los ascensores y escaleras.\n",
      "que hay de comer\n",
      "ROBOT: dependiendo de la naviera, para embarcar es conveniente llegar al embarque 3 o 4 horas antes de la hora de zarpar, normalmente los embarques suelen ser al mediodía y casi todas las compañías de cruceros ofrecen un buffet para comer.\n",
      "fin\n",
      "ROBOT: pipas, cigarrillos y puros están permitidos sólo en algunos lugares dedicados a tal fin.\n",
      "gracias\n",
      "ROBOT: No hay de qué\n",
      "salir\n",
      "ROBOT: Nos vemos pronto, ¡cuídate!\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ROBOT: Mi nombre es ROBOT. Contestaré a tus preguntas acerca de sus vacaciones en el crucero. Si quieres salir, escribe 'salir' \")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response = user_response.lower() #Convertimos a minúscula\n",
    "    \n",
    "    if(user_response!='salir'):\n",
    "        \n",
    "        if(user_response=='gracias' or user_response=='muchas gracias'): #Se podría haber definido otra función de coincidencia manual\n",
    "            flag=True\n",
    "            print(\"ROBOT: No hay de qué\")\n",
    "            \n",
    "        else:\n",
    "            if(saludos(user_response)!=None): #Si la palabra insertada por el usuario es un saludo (Coincidencias manuales definidas previamente)\n",
    "                print(\"ROBOT: \"+saludos(user_response))\n",
    "                \n",
    "            else: #Si la palabra insertada no es un saludo --> CORPUS\n",
    "                print(\"ROBOT: \",end=\"\") \n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response) # para eliminar del corpus la respuesta del usuario y volver a evaluar con el CORPUS limpio\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBOT: Nos vemos pronto, ¡cuídate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd6467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
